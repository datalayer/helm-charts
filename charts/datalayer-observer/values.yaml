observer:
  clusterType: any
  certificateIssuer: letsencrypt
  ingressClass: datalayer-traefik
  env:
    DATALAYER_RUN_HOST: "dev1.datalayer.run"

collector:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: role.datalayer.io/system
            operator: In
            values:
            - "true"
  # This is how prometheus discovers the opentelemetry collector
  serviceMonitor:
    enabled: true
    ## Scrape interval. If not set, the Prometheus default scrape interval is used.
    ##
    interval: ""
    ## Additional labels
    ##
    additionalLabels: {}
    #  foo: bar


#############################################################
## Install Opentelemetry Operator CRDs
#############################################################
crds:
  enabled: true

#############################################################
### Monitoring Stack : kube-prometheus-stack chart
#############################################################

## Prometheus, Grafana, and the rest of the kube-prometheus-stack are managed by the dependent chart here:
## https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack
## For sample values, please see their documentation.
kube-prometheus-stack:
  enabled: true
  defaultRules:
    create: true
    rules:
      alertmanager: false
  alertmanager:
    alertmanagerSpec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: role.datalayer.io/system
                operator: In
                values:
                - "true"
    serviceMonitor:
      additionalLabels:
        monitoring.datalayer.io/instance: "observer"
        monitoring.datalayer.io/enabled: "true"
  grafana:
    enabled: true
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: role.datalayer.io/system
              operator: In
              values:
              - "true"
    # Use random password at installation time for Grafana by default by setting empty value to `adminPassword`.
    # You can find out the actual password by running the following command:
    # kubectl get secret -l app.kubernetes.io/name=grafana -o=jsonpath="{.items[0].data.admin-password}" | base64 --decode
    adminPassword:
    serviceMonitor:
      enabled: true
      labels:
        monitoring.datalayer.io/instance: "observer"
        monitoring.datalayer.io/enabled: "true"
      path: /grafana/metrics
    ## Config to serve from sub_path
    # https://github.com/prometheus-community/helm-charts/issues/201
    # https://github.com/kubernetes/ingress-nginx/issues/6140#issuecomment-1132972644
    grafana.ini:
      server:
        serve_from_sub_path: true
    ingress:
      enabled: false
    sidecar:
      datasources:
        exemplarTraceIdDestinations:
          datasourceUid: tempo
          traceIdLabelName: TraceID
    additionalDataSources:
      - uid: loki
        orgId: 1
        name: Loki
        type: loki
        typeName: Loki
        access: proxy
        url: http://datalayer-observer-loki.datalayer-observer:3100
        password: ''
        user: ''
        database: ''
        basicAuth: false
        isDefault: false
        jsonData:
          derivedFields:
            - datasourceUid: tempo
              matcherRegex: (?:trace_id)=(\w+)
              name: TraceID
              url: $${__value.raw}
        readOnly: false
        editable: true
      - uid: tempo
        orgId: 1
        name: Tempo
        type: tempo
        typeName: Tempo
        access: proxy
        url: http://datalayer-observer-tempo.datalayer-observer:3100
        password: ''
        user: ''
        database: ''
        basicAuth: false
        isDefault: false
        jsonData:
          nodeGraph:
            enabled: true
          search:
            hide: false
          lokiSearch:
            datasourceUid: loki
          tracesToLogs:
            datasourceUid: loki
            filterBySpanID: false
            filterByTraceID: true
            mapTagNamesEnabled: false
            # FIXME
            tags:
              - compose_service
        readOnly: false
        editable: true
    # Configure Pulsar dashboards for Grafana
    dashboardProviders:
      dashboardproviders.yaml:
        apiVersion: 1
        providers:
          - name: "pulsar"
            orgId: 1
            folder: "Pulsar"
            type: file
            disableDeletion: true
            editable: true
            options:
              path: /var/lib/grafana/dashboards/pulsar
    dashboards:
      pulsar:
        # Download the maintained dashboards from AL 2.0 licenced repo https://github.com/streamnative/apache-pulsar-grafana-dashboard
        bookkeeper:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/bookkeeper.json
          datasource: Prometheus
        broker:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/broker.json
          datasource: Prometheus
        connector_sink:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/connector_sink.json
          datasource: Prometheus
        connector_source:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/connector_source.json
          datasource: Prometheus
        container:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/container.json
          datasource: Prometheus
        functions:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/functions.json
          datasource: Prometheus
        jvm:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/jvm.json
          datasource: Prometheus
        loadbalance:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/loadbalance.json
          datasource: Prometheus
        messaging:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/messaging.json
          datasource: Prometheus
        node:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/node.json
          datasource: Prometheus
        overview:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/overview.json
          datasource: Prometheus
        proxy:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/proxy.json
          datasource: Prometheus
        recovery:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/recovery.json
          datasource: Prometheus
        topic:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/topic.json
          datasource: Prometheus
        transaction:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/transaction.json
          datasource: Prometheus
        zookeeper:
          url: https://raw.githubusercontent.com/streamnative/apache-pulsar-grafana-dashboard/master/dashboards.kubernetes/zookeeper-3.6.json
          datasource: Prometheus
  prometheus:
    enabled: true
    prometheusSpec:
      routePrefix: /prometheus
      enableFeatures:
        - exemplar-storage
      # Scan all namespace for podMonitor
      podMonitorNamespaceSelector: {}
      podMonitorSelector:
        # Add pulsar podMonitors - currently the only one used
        matchExpressions:
          - key: app
            operator: In
            values: [pulsar]
      serviceMonitorSelector:
        matchLabels:
          monitoring.datalayer.io/instance: "observer"
          monitoring.datalayer.io/enabled: "true"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: role.datalayer.io/system
                operator: In
                values:
                - "true"
    serviceMonitor:
      additionalLabels:
        monitoring.datalayer.io/instance: "observer"
        monitoring.datalayer.io/enabled: "true"
    ingress:
      enabled: false
  prometheus-node-exporter:
    enabled: true
    prometheus:
      monitor:
        additionalLabels:
          monitoring.datalayer.io/instance: "observer"
          monitoring.datalayer.io/enabled: "true"
  prometheusOperator:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: role.datalayer.io/system
              operator: In
              values:
              - "true"
    serviceMonitor:
      additionalLabels:
        monitoring.datalayer.io/instance: "observer"
        monitoring.datalayer.io/enabled: "true"
    admissionWebhooks:
      deployment:
        nodeSelector:
          role.datalayer.io/system: "true"
      patch:
        nodeSelector:
          role.datalayer.io/system: "true"

loki:
  enabled: true
  deploymentMode: SingleBinary
  loki:
    commonConfig:
      replication_factor: 1
    # See https://grafana.com/docs/loki/latest/operations/multi-tenancy/
    auth_enabled: false
    limits_config:
      allow_structured_metadata: true
    storage:
      type: 'filesystem'
    schemaConfig:
      configs:
      - from: "2024-01-01"
        store: tsdb
        index:
          prefix: loki_index_
          period: 24h
        object_store: filesystem # we're storing on filesystem so there's no real persistence here.
        schema: v13
  gateway:
    enabled: false
  # FIXME this is deprecated
  monitoring:
    dashboards:
      enabled: true
    serviceMonitor:
      enabled: true
      labels:
        monitoring.datalayer.io/instance: "observer"
        monitoring.datalayer.io/enabled: "true"
  singleBinary:
    replicas: 1
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: role.datalayer.io/system
              operator: In
              values:
              - "true"
  read:
    replicas: 0
  backend:
    replicas: 0
  write:
    replicas: 0
  resultsCache:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: role.datalayer.io/system
              operator: In
              values:
              - "true"
  chunksCache:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: role.datalayer.io/system
              operator: In
              values:
              - "true"

# https://github.com/grafana/helm-charts/tree/main/charts/tempo
tempo:
  enabled: true
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: role.datalayer.io/system
            operator: In
            values:
            - "true"
  # persistence:
  #   enabled: true
  receivers:
    jaeger: null
  serviceMonitor:
    enabled: true
    additionalLabels:
      monitoring.datalayer.io/instance: "observer"
      monitoring.datalayer.io/enabled: "true"
  reportingEnabled: false

#############################################################
## OpenTelemetry operator
#############################################################

opentelemetry-operator:
  enabled: true
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: role.datalayer.io/system
            operator: In
            values:
            - "true"
  manager:
    collectorImage:
      repository: otel/opentelemetry-collector-contrib
    serviceMonitor:
      enabled: true
      extraLabels:
        monitoring.datalayer.io/instance: "observer"
        monitoring.datalayer.io/enabled: "true"
  crds:
    create: false
